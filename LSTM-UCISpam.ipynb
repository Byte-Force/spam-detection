{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-18T17:56:05.392725764Z",
     "start_time": "2023-07-18T17:56:05.379334004Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# define parameters\n",
    "SEED = 1234\n",
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T17:56:05.394724658Z",
     "start_time": "2023-07-18T17:56:05.381094265Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ShresthaSudip/SMS_Spam_Detection_DNN_LSTM_BiLSTM/master/SMSSpamCollection'\n",
    "messages = pd.read_csv(url, sep ='\\t',names=[\"label\", \"message\"])\n",
    "messages.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T17:56:05.589454771Z",
     "start_time": "2023-07-18T17:56:05.387980617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "print(messages.groupby(\"label\").describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "messages[\"Message Length\"]=messages[\"message\"].apply(len)\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "sns.histplot(\n",
    "    x=messages[\"Message Length\"],\n",
    "    hue=messages[\"label\"]\n",
    ")\n",
    "plt.title(\"ham & spam messege length comparision\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "ham_desc=messages[messages[\"label\"]==\"ham\"][\"Message Length\"].describe()\n",
    "spam_desc=messages[messages[\"label\"]==\"spam\"][\"Message Length\"].describe()\n",
    "\n",
    "print(\"Ham Messege Length Description:\\n\",ham_desc)\n",
    "print(\"************************************\")\n",
    "print(\"Spam Message Length Description:\\n\",spam_desc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    data=messages,\n",
    "    x=\"label\"\n",
    ")\n",
    "plt.title(\"ham vs spam\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning (undersampling for imbalanced data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "#compute the length of majority & minority class\n",
    "minority_len=len(messages[messages[\"label\"]==\"spam\"])\n",
    "majority_len=len(messages[messages[\"label\"]==\"ham\"])\n",
    "\n",
    "#store the indices of majority and minority class\n",
    "minority_indices=messages[messages[\"label\"]==\"spam\"].index\n",
    "majority_indices=messages[messages[\"label\"]==\"ham\"].index\n",
    "\n",
    "#generate new majority indices from the total majority_indices\n",
    "#with size equal to minority class length so we obtain equivalent number of indices length\n",
    "random_majority_indices=np.random.choice(\n",
    "    majority_indices,\n",
    "    size=minority_len,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "#concatenate the two indices to obtain indices of new dataframe\n",
    "undersampled_indices=np.concatenate([minority_indices,random_majority_indices])\n",
    "\n",
    "#create df using new indices\n",
    "df=messages.loc[undersampled_indices]\n",
    "\n",
    "#shuffle the sample\n",
    "df=df.sample(frac=1)\n",
    "\n",
    "#reset the index as its all mixed\n",
    "df=df.reset_index()\n",
    "\n",
    "#drop the older index\n",
    "df=df.drop(\n",
    "    columns=[\"index\"],\n",
    ")\n",
    "print(\"df shape: \", df.shape)\n",
    "df['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[\"label\"].map(\n",
    "    {\n",
    "        \"ham\":0,\n",
    "        \"spam\":1\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df.to_csv(\"df.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Processing and Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import warnings as wrn\n",
    "import spacy\n",
    "wrn.filterwarnings(\"ignore\")\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "text = data.Field(tokenize=lambda text: [tok.text for tok in spacy_en(text)], batch_first=True, include_lengths=True)\n",
    "label = data.LabelField(dtype = torch.float,batch_first=True)\n",
    "\n",
    "fields = [(\"label\",label),('text',text)]\n",
    "\n",
    "# load data from df\n",
    "training_data=data.TabularDataset(\n",
    "    path=\"df.csv\",\n",
    "    format=\"csv\",\n",
    "    fields=fields,\n",
    "    skip_header=True,\n",
    ")\n",
    "print(vars(training_data.examples[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, test_data = training_data.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
    "text.build_vocab(train_data, min_freq=3, vectors=\"glove.6B.100d\")\n",
    "label.build_vocab(train_data)\n",
    "print(\"Size of text vocab: \", len(text.vocab))\n",
    "print(\"Size of label vocab: \", len(label.vocab))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "text.vocab.freqs.most_common(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Building & Data Loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # lstm layer -> output_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        # dense layer -> prediction\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        return self.act(self.fc(hidden.squeeze(0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "SIZE_OF_VOCAB = len(text.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "NUM_EPOCHS = 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "model = LSTM(SIZE_OF_VOCAB, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "model = model.to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float() # convert into float for division\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'LSTM-UCIspam-model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fine-tuning with our own data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# fine tune with our fine-tune-dataset.csv\n",
    "import pandas as pd\n",
    "ft_df = pd.read_csv(\"fine-tune-dataset.csv\")\n",
    "\n",
    "# tokenize\n",
    "ft_df['text'] = ft_df['text'].apply(lambda x: [tok.text for tok in spacy_en(x)])\n",
    "\n",
    "# use all data to train\n",
    "ft_data=data.TabularDataset(\n",
    "    path=\"fine-tune-dataset.csv\",\n",
    "    format=\"csv\",\n",
    "    fields=fields,\n",
    "    skip_header=True,\n",
    ")\n",
    "\n",
    "# build vocab\n",
    "text.build_vocab(ft_data, min_freq=3, vectors=\"glove.6B.100d\")\n",
    "label.build_vocab(ft_data)\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load('LSTM-UCIspam-model.pt'))\n",
    "model = model.to(device)\n",
    "\n",
    "# training\n",
    "train_iterator = data.BucketIterator(\n",
    "    ft_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing with some examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1 = \"Limited time offer! Buy one, get one free on all online courses!\"\n",
    "t2 = \"Just finished my final exams! Looking forward to a relaxing summer break. What are some places you recommend for a vacation?\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
